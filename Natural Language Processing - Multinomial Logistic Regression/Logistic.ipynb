{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression\n",
    "\n",
    "## Arguments\n",
    "\n",
    "1) train input: path to the training input .tsv file \n",
    "\n",
    "2) validation input: path to the validation input .tsv file \n",
    "\n",
    "3) test input: path to the test input .tsv file \n",
    "\n",
    "4) train out: path to output .labels file to which the prediction on the training data should be written \n",
    "\n",
    "5) test out: path to output .labels file to which the prediction on the test data should be written\n",
    "\n",
    "6) metrics out: path of the output .txt file to which metrics such as train and test error should be written\n",
    "\n",
    "7) num epoch: integer specifying the number of times SGD loops through all of the training data\n",
    "(e.g., if num epoch equals 5, then each training example will be used in SGD 5 times).\n",
    "    \n",
    "8) feature flag: integer taking value 1 or 2 that specifies whether to construct the Model 1 feature set or the Model 2 feature set â€”that is, if feature_flag==1 use Model 1 features; if feature_flag==2 use Model 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train= sys.argv[1]\n",
    "#train_d= data(f_train)\n",
    "\n",
    "\n",
    "f_validation = sys.argv[2]\n",
    "#validation_d = data(f_validation)\n",
    "f_test = sys.argv[3]\n",
    "#test_d= data(f_test)\n",
    "trainlabels = sys.argv[4]\n",
    "testlabels = sys.argv[5]\n",
    "metrics = sys.argv[6]\n",
    "Epoch = int(sys.argv[7])\n",
    "t_M = sys.argv[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data:\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        data = []\n",
    "        data.append(['B','O'])\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.lines = []\n",
    "\n",
    "        with open(file_name, 'r') as openf:\n",
    "            for line in openf:\n",
    "                self.lines.append(line)\n",
    "                if line != '\\n':\n",
    "                    data.append(line.replace('\\n', '').split('\\t'))\n",
    "                else:\n",
    "                    data.append(['E','O'])\n",
    "                    data.append(['B','O'])\n",
    "        data.append(['E','O'])\n",
    "\n",
    "        for i in data:\n",
    "            self.x.append(i[0])\n",
    "            self.y.append(i[1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class matrix:\n",
    "\n",
    "    def __init__(self, data,t_M, attrib, labels):\n",
    "\n",
    "        k = len(labels)\n",
    "\n",
    "        if t_M == '1':\n",
    "\n",
    "            data_x = []\n",
    "            data_y = []\n",
    "            for i, row in enumerate(data.x):\n",
    "                if (row != 'E') and (row != 'B'):\n",
    "                    for j, input in enumerate(attrib):\n",
    "                        if input == data.x[i]:\n",
    "                            data_x.append(j)\n",
    "                            continue\n",
    "                    for j, label in enumerate(labels):\n",
    "                        if label == data.y[i]:\n",
    "                            data_y.append(j)\n",
    "                            continue\n",
    "\n",
    "            n = len(data_x)\n",
    "            m = len(attrib) + 1 \n",
    "            self.x = np.zeros((n, m), dtype=int)\n",
    "            for i, row in enumerate(data_x):\n",
    "                self.x[i, -1] = 1  #bias term\n",
    "                self.x[i, row] = 1\n",
    "            self.y = np.array(data_y)\n",
    "\n",
    "        elif t_M == '2':\n",
    "\n",
    "            data_x = []\n",
    "            data_y = []\n",
    "            for i, row in enumerate(data.x):\n",
    "                if (row != 'E') and (row != 'B'):\n",
    "                    for j, input in enumerate(attrib):\n",
    "                        if input == data.x[i-1]:\n",
    "                            x1 = j\n",
    "                        elif input == data.x[i]:\n",
    "                            x2 = j\n",
    "                        elif input == data.x[i+1]:\n",
    "                            x3 = j\n",
    "                    data_x.append([x1, x2, x3])\n",
    "\n",
    "                    for j, label in enumerate(labels):\n",
    "                        if label == data.y[i]:\n",
    "                            data_y.append(j)\n",
    "                            continue\n",
    "\n",
    "            n = len(data_x)\n",
    "            m = len(attrib) * 3 + 1 #  \n",
    "            self.x = np.zeros((n, m), dtype=int)\n",
    "            for i, row in enumerate(data_x):\n",
    "                for j, col in enumerate(row):\n",
    "                    self.x[i, j * len(attrib) + col] = 1 \n",
    "                self.x[i, -1] = 1\n",
    "            self.y = np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ji(x, y, theta):\n",
    "    value=0\n",
    "    n = x.shape[0]\n",
    "    m = x.shape[1]\n",
    "    k = theta.shape[0]\n",
    "    mat = np.zeros((n, k))\n",
    "    for i in range(n):\n",
    "        mat[i][y[i]] = 1\n",
    "    value = -(1./n) * ( mat.T * (np.dot(x, theta.T).T - np.log(np.exp(np.dot(x, theta.T)).sum(axis=1))) ).sum()\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(x, y, step, theta):\n",
    "    n = x.shape[0]\n",
    "    m = x.shape[1]\n",
    "    k = theta.shape[0]\n",
    "    for i in range(n):\n",
    "        mat = np.zeros(k)\n",
    "        mat[y[i]] = 1\n",
    "        dj = - np.outer(( mat - np.exp(np.dot(x[i], theta.T)) / np.exp(np.dot(x[i], theta.T)).sum() ), x[i])\n",
    "        theta = theta - step * dj\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x, theta):\n",
    "\n",
    "    max_val = np.argmax(np.dot(x, theta.T), axis=1)\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_d= data(f_train)\n",
    "    validation_d = data(f_validation)\n",
    "    test_d= data(f_test)\n",
    "    attrib = np.unique(train_d.x)\n",
    "    labels = np.sort(np.unique(train_d.y)) \n",
    "    v_tr = matrix(train_d, t_M, attrib, labels)\n",
    "    v_v = matrix(validation_d,t_M,attrib, labels)\n",
    "    v_te = matrix(test_d,t_M,attrib, labels)\n",
    "\n",
    "    k = len(labels)\n",
    "    step = 0.5\n",
    "    metric = ''\n",
    "    \n",
    "    if t_M == '1':\n",
    "        m = len(attrib) + 1 # with bias term \n",
    "    elif t_M == '2':\n",
    "        m = len(attrib) * 3 + 1\n",
    "        \n",
    "    theta = np.zeros((k, m))\n",
    "\n",
    "    for i in range(Epoch):\n",
    "\n",
    "        theta = GD(v_tr.x, v_tr.y, step, theta)\n",
    "\n",
    "        J_train = Ji(v_tr.x, v_tr.y, theta)\n",
    "        J_validation = Ji(v_v.x, v_v.y, theta)\n",
    "\n",
    "        metric += 'epoch={} likelihood(train): {:.6f}\\n'.format(i+1, J_train)\n",
    "        metric += 'epoch={} likelihood(validation): {:.6f}\\n'.format(i+1, J_validation)\n",
    "\n",
    "    p_train = pred(v_tr.x, theta)\n",
    "    error_train = 1 - float(sum(p_train==v_tr.y))/len(v_tr.x)\n",
    "    metric += 'error(train): {:.6f}\\n'.format(error_train)\n",
    "\n",
    "    p_test = pred(v_te.x, theta)\n",
    "    error_test = 1 - float(sum(p_test==v_te.y))/len(v_te.x)\n",
    "    metric += 'error(test): {:.6f}\\n'.format(error_test)\n",
    "\n",
    "    labels_train = ''\n",
    "    counter = 0\n",
    "    for line in train_d.lines:\n",
    "        if line != '\\n':\n",
    "            labels_train += labels[p_train[counter]]\n",
    "            labels_train += '\\n'\n",
    "            counter += 1\n",
    "        else:\n",
    "            labels_train += '\\n'\n",
    "\n",
    "    labels_test = ''\n",
    "    counter = 0\n",
    "    for line in test_d.lines:\n",
    "        if line != '\\n':\n",
    "            labels_test += labels[p_test[counter]]\n",
    "            labels_test += '\\n'\n",
    "            counter += 1\n",
    "        else:\n",
    "            labels_test += '\\n'\n",
    "\n",
    "    with open(metrics, 'w') as f:\n",
    "        f.write(metric)\n",
    "    f.closed\n",
    "    with open(trainlabels, 'w') as f:\n",
    "        f.write(labels_train)\n",
    "    f.closed\n",
    "    with open(testlabels, 'w') as f:\n",
    "        f.write(labels_test)\n",
    "    f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
