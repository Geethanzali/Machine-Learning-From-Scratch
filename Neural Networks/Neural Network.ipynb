{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## **Arguments:**\n",
    "\n",
    "1) **train input**: path to the training input .csv file\n",
    "\n",
    "2) **validation input**: path to the validation input .csv file\n",
    "\n",
    "3) **train out**: path of output .labels file to which the predictions on the training data should be written\n",
    "\n",
    "4) **validation out**: path to output .labels file to which the prediction on the validation data should be written\n",
    "    \n",
    "5) **metrics out**: path of the output .txt file to which metrics such as train and validation error should be written\n",
    "    \n",
    "6) **num epoch**: integer specifying the number of times backpropogation loops through all of the training data \n",
    "\n",
    "7) **hidden units**: positive integer specifying the number of hidden units.\n",
    "    \n",
    "8) **init flag**: integer taking value 1 or 2 that specifies whether to use RANDOM or ZERO initialization\n",
    "\n",
    "that is, if init_flag==1 initialize your weights randomly from a uniform distribution over the range [-0.1,0.1] (i.e. RANDOM), if init_flag==2 initialize all weights to zero (i.e. ZERO). For both settings, always initialize bias terms to zero.\n",
    "\n",
    "9) **learning rate**: float value specifying the learning rate for SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import csv \n",
    "train_input = sys.argv[1] \n",
    "validation_input = sys.argv[2]\n",
    "train_out = sys.argv[3]\n",
    "validation_out = sys.argv[4]\n",
    "metrics_out = sys.argv[5]\n",
    "epoch = int(sys.argv[6])\n",
    "hidden_units = int(sys.argv[7])\n",
    "init_flag = sys.argv[8]\n",
    "learning_rate = float(sys.argv[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    \n",
    "    train = file_data(train_input)\n",
    "    validation = file_data(validation_input)\n",
    "    \n",
    "    numofattributes= train.dim_x\n",
    "    numofy=train.dim_y\n",
    "    labels_t= train.y\n",
    "    labels_v=validation.y\n",
    "    yval_train= train.labely\n",
    "    yval_vali= validation.labely\n",
    "    attrib_train= train.x\n",
    "    attrib_vali= validation.x\n",
    "    numofex_train= train.trainingex\n",
    "    numofex_vali= validation.trainingex\n",
    "    \n",
    "    alpha = np.asmatrix(np.random.uniform(-0.1,0.1,(hidden_units,numofattributes)))\n",
    "    beta = np.asmatrix(np.random.uniform(-0.1,0.1,(numofy,hidden_units+1)))\n",
    "    if init_flag == '1':\n",
    "        alpha = np.asmatrix(np.random.uniform(-0.1,0.1,(hidden_units,numofattributes)))\n",
    "        alpha = np.insert(alpha,0,0.0,axis=1)\n",
    "        beta = np.asmatrix(np.random.uniform(-0.1,0.1,(numofy,hidden_units)))\n",
    "        beta = np.insert(beta,0,0.0,axis=1)\n",
    "    elif init_flag == '2':\n",
    "        alpha = np.zeros((hidden_units,numofattributes+1))\n",
    "        beta = np.zeros((numofy,hidden_units+1))\n",
    "        \n",
    "    \n",
    "    modelmetrics = ''\n",
    "    \n",
    "    \n",
    "    for i in range(epoch):\n",
    "        J_t = []\n",
    "        \n",
    "        for j in range(0,numofex_train):\n",
    "            gA1,gB1= backward(attrib_train,labels_t,yval_train,alpha,beta,learning_rate,j)\n",
    "            beta= beta- learning_rate*gB1\n",
    "            alpha= alpha-learning_rate*gA1\n",
    "            \n",
    "        for j in range(0,numofex_train):\n",
    "            a,zm1,z,b,yc,y_te,jtotal_t,pred_t= forward(attrib_train,labels_t,yval_train,alpha,beta,learning_rate,j)\n",
    "            J_t.append(jtotal_t)\n",
    "#            print(\"trip\")\n",
    "#            print(a)\n",
    "#            print(zm1)\n",
    "#            print(z)\n",
    "#            print(jtotal_t)\n",
    "            #Pred_t.append(pred_t)\n",
    "        \n",
    "        J_train= np.sum(J_t)/numofex_train\n",
    "        print(J_train)\n",
    "        modelmetrics += 'epoch={} crossentropy(train): {:.11f}\\n'.format(i+1, J_train)\n",
    "        print(modelmetrics)\n",
    "        J_v = []\n",
    "        Pred_v=[]\n",
    "        for j in range(0,numofex_vali):\n",
    "            a_v,zm1_v,z_v,b_v,yc_v,y_te_v,jtotal_v,pred_v = forward(attrib_vali,labels_v,yval_vali,alpha,beta,learning_rate,j)\n",
    "            J_v.append(jtotal_v)\n",
    "            #Pred_v.append(pred_v)\n",
    "            \n",
    "        J_validation= np.sum(J_v)/numofex_vali\n",
    "\n",
    "        modelmetrics += 'epoch={} crossentropy(validation): {:.11f}\\n'.format(i+1, J_validation)\n",
    "        print(\"jugnu\")\n",
    "        print(modelmetrics)\n",
    "    \n",
    "    Pred_t=[]\n",
    "    for j in range(0,numofex_train):\n",
    "        a,zm1,z,b,yc,y_te,jtotal_t,pred_t= forward(attrib_train,labels_t,yval_train,alpha,beta,learning_rate,j)\n",
    "        Pred_t.append(pred_t)\n",
    "    \n",
    "    Pred_v=[]\n",
    "    for j in range(0,numofex_vali):\n",
    "        a_v,zm1_v,z_v,b_v,yc_v,y_te_v,jtotal_v,pred_v = forward(attrib_vali,labels_v,yval_vali,alpha,beta,learning_rate,j)\n",
    "        Pred_v.append(pred_v)\n",
    "\n",
    "\n",
    "    error_train = 1 - float(sum(Pred_t==yval_train))/len(yval_train)\n",
    "    modelmetrics += 'error(train): {:.2f}\\n'.format(error_train)\n",
    "    error_val = 1 - float(sum(Pred_v==yval_vali))/len(yval_vali)\n",
    "    modelmetrics += 'error(validation): {:.2f}\\n'.format(error_val)\n",
    "\n",
    "\n",
    "    labels_train = ''\n",
    "    for i in range(len(Pred_t)):\n",
    "        labels_train = labels_train + str(Pred_t[i]) + '\\n'    \n",
    "\n",
    "    labels_val = ''\n",
    "    for i in range(len(Pred_v)):\n",
    "        labels_val = labels_val + str(Pred_v[i]) + '\\n'   \n",
    "#    \n",
    "#       \n",
    "    with open(metrics_out, 'w') as f:\n",
    "        f.write(modelmetrics)\n",
    "    f.closed\n",
    "    with open(train_out, 'w') as f:\n",
    "        f.write(labels_train)\n",
    "    f.closed\n",
    "    with open(validation_out, 'w') as f:\n",
    "        f.write(labels_val)\n",
    "    f.closed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):     \n",
    "    zm1= 1.0/(1.0+np.exp(-a))\n",
    "    z=np.insert(zm1,0,1.0,axis=0)\n",
    "    return [zm1,z]\n",
    "\n",
    "def softmax(b):\n",
    "    yc= np.exp(b)/np.sum(np.exp(b))\n",
    "    return yc\n",
    "\n",
    "def forward(x1,yunique1, y1, alpha, beta, eta,t):\n",
    "    x = np.matrix(x1)\n",
    "    y = np.matrix(y1)\n",
    "    \n",
    "    #yunique = np.matrix(yunique1)\n",
    "    a= np.dot(alpha,np.transpose(x[t]))\n",
    "    zm1,z = sigmoid(a)\n",
    "    #z1 = np.matrix(z)\n",
    "    b= np.dot(beta,z)\n",
    "    \n",
    "    yc = softmax(b) #10x1\n",
    "    A = np.array(yc) \n",
    "    p = np.argmax(A)\n",
    "    #print p\n",
    "    y_te = yunique1[int(y1[t])]\n",
    "    \n",
    "    J= -float(np.dot(y_te,np.log(yc)))\n",
    "    return [a,zm1,z,b,yc,y_te,J,p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x1,yunique1, y1, alpha, beta, eta,t):\n",
    "    x = np.matrix(x1)\n",
    "    y = np.matrix(y1)\n",
    "    \n",
    "    a,zm1,z,b,yc,y_te,J,p = forward(x1,yunique1, y1, alpha, beta, eta,t)\n",
    "    yunique = np.matrix(y_te)\n",
    "    gy= -np.divide(yunique,np.transpose(yc)) #1x10\n",
    "    \n",
    "    ycc = np.matrix(yc)\n",
    "    ycd= np.diagflat(ycc) #10x10\n",
    "    gb=np.dot(gy,(ycd - yc*np.transpose(yc))) #1x10\n",
    "    \n",
    "\n",
    "        \n",
    "    gB= np.transpose(gb)*np.transpose(z) #10x5\n",
    "    \n",
    "        \n",
    "    gz= np.transpose(beta)*np.transpose(gb) #5x10 * 10x1 #5x1\n",
    "    \n",
    "    beta_new = np.delete(beta,0,1)\n",
    "    \n",
    "    gz1= np.transpose(beta_new)*np.transpose(gb) #4x1\n",
    "\n",
    "    ga= np.multiply(np.multiply(gz1,zm1),1-zm1) #4x1\n",
    "    gA= ga*x[t] #4x1 * 1x129\n",
    "    \n",
    "    return [gA,gB]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class file_data:\n",
    "    def __init__(self, file_path):\n",
    "        \n",
    "        reader = csv.reader(open(file_path, \"rb\"), delimiter=\",\")\n",
    "        x1 = list(reader)\n",
    "        result = np.matrix(x1).astype(\"float\")\n",
    "        r= np.delete(result,0,1)  #x matrix without bias\n",
    "        self.trainingex=len(r)\n",
    "        self.dim_x= (np.prod(r.shape)/len(r))\n",
    "        self.labely= (np.asarray(result[:,0]).reshape(-1))\n",
    "        self.y1= (np.unique(self.labely))\n",
    "        y2 = np.diagflat(self.y1)\n",
    "        self.y = np.identity(y2.shape[0])\n",
    "        \n",
    "        \n",
    "        self.dim_y= (len(np.unique(self.labely)))\n",
    "        self.x= np.insert(r,0,1.0,axis=1)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
